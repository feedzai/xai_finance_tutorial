# [Explainable AI in Financial Services](https://feedzai.github.io/xai_finance_tutorial/)

## Presenters

* Sergio Jesus - Feedzai, DCC-FCUP Universidade do Porto
* João Bento - Feedzai
* Vladimir Balayan - Feedzai
* Catarina Belém - Feedzai
* André Cruz - Feedzai
* Pedro Saleiro - Feedzai
* Pedro Bizarro - Feedzai


## Why this tutorial?

The recent interest in Explainable AI (XAI) is a consequence of the black-box paradigm in AI. This is especially relevant if the ML
model is integrated into a high-stakes decision system, such as in healthcare, legal, or financial systems. However, there are several
obstacles to the adoption of explainability methods, namely:

1. The difficulty of evaluating the effectiveness and trustworthiness of these algorithms.
2. The interpretability of the results.
3. The parameterization and stochastic nature of the algorithms.

This tutorial serves as a thorough introduction to several concepts of Explainable AI (XAI) both in theory and practice. By addressing real-world
scenarios in financial services tasks (e.g., fraud prevention), this tutorial provides hands-on knowledge on how to incorporate XAI approaches into ML
systems.

## What will we cover?

This tutorial will start with general definitions and objectives regarding the Explainable AI (XAI) field. Then we will present existing state-of-the-art explainability methods, their relevancy, differences, and possible applications, given the context of financial services. Finally, we will discuss the objectives for explainability of the different stakeholders involved, focusing on Data Scientists and Humans-in-the-loop, and how to evaluate explanations for a given persona and use-case. With this tutorial, the audience will have a clear understanding of which methods and steps exist and are necessary to integrate XAI in real-world use-cases.

## Pre-Requisites
- Prior experience with Machine Learning theory.
- Programming (in Python) - For practical part of tutorial.

## Schedule and Structure

1. What is XAI.

2. XAI in Financial Services.

3. XAI Overview
    * Transparency and Explainability definitions.
    * Data Explainers.
    * In-model Explainers.
    * Post-model Explainers.
    * Explanation output.
    * Explainability methods’ techniques.

4. State-of-the-Art methods deep-dive
    * Introduction to methods for tabular data.
    * Adaptation to recurrent scenarios.
    * Self-explainable models.
    * Practical tools overview.
    
5. Evaluation of Explainability methods
    * Common desiderata.
    * Different Personas and information needs.
    * How to conduct an experiment in XAI.
    * Multiple XAI methods comparison.
    * Dangers of blind XAI usage in real world applications.

6. Final remarks.

## Resources

Will be available near the conference date!



## References

[1] V. Balayan, P. Saleiro, C. Belém, L. Krippahl, and P. Bizarro, “Teaching the machine to explain itself using domain knowledge,” in NeurIPS 2020 Workshop on Human And Model in the Loop Evaluation and Training Strategies, 2020. Available: https://hamlets-workshop.github.io/schedule/

[2] S. Jesus, C. Belém, V. Balayan, J. Bento, P. Saleiro, P. Bizarro, and J.Gama, “How can i choose an explainer? an application-grounded evaluation of post-hoc explanations,” in Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, FAccT ’21, Association  for  Computing  Machinery, 2021, pp. 805–815. Available:https://doi.org/10.1145/3442188.3445941.

[3] C. Belém, V. Balayan, P. Saleiro, and P. Bizarro, “Weakly supervised multi-task learning for concept-based explainability,” in International Conference on Learning Representations 2021 Workshop on Weakly Supervised Learning, 2021. Available:https://weasul.github.io/accpapers/.

[4]    J. Bento, P. Saleiro, A. F. Cruz, M. A. T. Figueiredo, and P. Bizarro, "TimeSHAP: Explaining Recurrent Models through Sequence Perturbations", in  Proc. of the 27th ACM SIGKDD Int. Conf. on Knowledge Discovery and Data Mining, (KDD), 2021. 
